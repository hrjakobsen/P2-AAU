\section{Discussion}
We started out by using the relatively simple LSB-method for hiding data in an image.
Specifically we saved an image inside of another PNG-image.
While the differences in the image with and without the message-image were hardly noticeable to the human eye, we did find that comparing colour histograms of the two images revealed that there had in fact been made changes to it.
In an effort to diminish this problem, the graph-theoretical approach we implemented attempted to move pixels around in the image, rather than change their values.
This meant that colour histograms of the image before and after the message had been encoded should look very similar, almost identical.
Any changes would come from the unmatched pairs: the quantized DCT values used in the encoding that we did not find any interchangeable values for.
When this happened we were forced to change the individual values, which led to a change in the colour composition of the image.
Using this method, we expected the changes to be small enough so that it would not immediately draw attention to the image, if it was being subjected to a colour histogram.

To find out roughly how many of these forces there were in a given image, we used our programme to save different messages in different images.
The used five different message lengths: 70, 140, 280, 560 and 1120 bytes.
Each message consisted of the ASCII characters A-Z repeated to fill out the message.
Each of these messages were encoded in four images with varying motives, but the same resolution (1920x1080).
The images can be seen in figure \ref{fig:four_test_images}.
We used a cartoon-like drawing of a cat to see how our software would work on an image that was not ideal for the JPEG format.
The landscape image contained many different colours and very complex patterns, which made it ideal for JPEG compression.
The same could be said for the tiger, but it contained larger areas of similar colours than the landscape did.
The image of the snowy forest road contained very few colour nuances, but was almost made up of the luminance channel.
This led to a total of 20 tests as seen in table \ref{fig:forces_swaps}.

\vspace{12pt}
\begin{table}[]
\centering
\begin{tabular}{@{}lllll@{}}
\textbf{Image}                      & \textbf{Message length} & \textbf{Swaps} & \textbf{Forces} & \textbf{Already fit} \\ \midrule
\multirow{5}{*}{\textit{Cat}}       & 70                      & 56\%           & 19\%            & 26\%                 \\
                                    & 140                     & 58\%           & 18\%            & 24\%                 \\
                                    & 280                     & 65\%           & 12\%            & 23\%                 \\
                                    & 560                     & 65\%           & 11\%            & 24\%                 \\
                                    & 1120                    & 66\%           & 8\%             & 25\%                 \\ \midrule
\multirow{5}{*}{\textit{Landscape}} & 70                      & 55\%           & 15\%            & 30\%                 \\
                                    & 140                     & 63\%           & 11\%            & 27\%                 \\
                                    & 280                     & 62\%           & 11\%            & 27\%                 \\
                                    & 560                     & 62\%           & 13\%            & 25\%                 \\
                                    & 1120                    & 63\%           & 12\%            & 25\%                 \\ \midrule
\multirow{5}{*}{\textit{Tiger}}     & 70                      & 63\%           & 8\%             & 28\%                 \\
                                    & 140                     & 64\%           & 8\%             & 27\%                 \\
                                    & 280                     & 68\%           & 6\%             & 26\%                 \\
                                    & 560                     & 70\%           & 5\%             & 25\%                 \\
                                    & 1120                    & 72\%           & 4\%             & 24\%                 \\ \midrule
\multirow{5}{*}{\textit{Snow}}      & 70                      & 53\%           & 21\%            & 26\%                 \\
                                    & 140                     & 58\%           & 13\%            & 29\%                 \\
                                    & 280                     & 66\%           & 8\%             & 26\%                 \\
                                    & 560                     & 67\%           & 8\%             & 25\%                 \\
                                    & 1120                    & 69\%           & 7\%             & 24\%                 \\ \bottomrule
\end{tabular}
	\caption{The percentages of values which the program swapped or forced. Since this was run with M = 4, about a fourth of the values already fit.}
	\label{fig:forces_swaps}
\end{table}

It became apparent that a longer message required fewer forces. 
This made sense, seeing as a longer message meant a larger graph with more edges and therefore possible ways of swapping values.
During development of the programme we played around with the idea of using more vertices than what was required for the message, as we predicted it would mean fewer forces.
These predictions would seem to be correct, but we never implemented the idea for two reasons.
One, we were not entirely certain how to do it: should we just use twice as much as was actually needed?
This would lead to using much more than what was necessary with a longer message, since the improvement quickly diminishes with longer messages.
Instead it would make more sense to always use a certain minimum of values, so shorter messages could be encoded properly, but longer ones did not take too long to encode.
What were to happen if the image simply did not contain enough values then? 
Should the programme inform the user that they needed to use a larger image or attempt to encode the message with the vertices it could make?
What would this mean for the \lstinline|GetCapacity| method? 
Should it take into consideration these extra values or just ignore it entirely?
An entirely different approach would be to let the user decide themselves, how many values they wished the algorithm to use. 
Presenting this in a user-friendly way constituted a challenge in itself though.

The second reason we did not implement it was due to performance concerns.
Since our programme performed rather poorly during most of the development we considered it a very bad idea to construct a larger graph than we already were constructing.
Seeing as we managed to optimise the programme quite significantly, we could have properly implemented a solution regardless.

Actually comparing colour histograms from the two methods was not as trivial as one could have hoped.
Using the LSB-method only made immediately visible changes to the colour histograms if about a quarter of the image had data encoded in it.
When using an image of substantial size, a quarter of an image can hold a large amount of data. 
A 512x512 image for example can hold 196,604 bytes, when using the two least significant bits.
Encoding 40,000 bytes using our graph-theoretical (GT) programme was completely out of the question due to the complexity of the algorithm.
The longest message we tried encoding was just under 8960 bytes and took around half an hour on a decent desktop computer.
Running several test runs with different message lengths made it clear that the complexity of the programme made it impossible to ever complete an encoding of this much data.

This made a direct comparison using realistic real-world images and messages impossible. 
The only real comparison we could make was between images containing different messages that used up every single available byte in the image.
Since the GT method became very time consuming with larger messages, we would need to use an image that was small enough that we could embed all bytes possible, without it taking too long to complete.
We ended up using a


A different way of looking for changes in an image is by looking at their Euclidean distance.
This can be done by calculating the distance between the colour values of each pixel in two equally sized images.
The sum of all these distances can be used as measure of the change from one image to the other.
We used this same method for determining what changes were imposed on images of different size and format, when uploaded to various social media and image-sharing websites.

Comparing these results directly with the ones obtained from the LSB-method would be folly.
While the LSB-method would certainly incur a smaller difference in the Euclidean distance it would not necessarily make it any better.
First of all using this method required that the user was in possession of both the original and the stego image.
This would indeed be possible if the parties sharing secret messages in the images, were using images they found on the internet and tampered with them.
They could completely foil this risk of being compromised then, by simply using images that they took themselves.
The other reason for the differences being larger is due to how the JPEG-file format is encoded.
Using the LSB of every pixel there is only the potential to change the value of each pixel by one.
Using the graph-theoretical approach with an M value of four, means that each individual value can be changed by four. 
This change is applied after the quantization step to avoid losing the data again.
This in turn means that the small change of up to four is multiplied by the quantization table, when the image is shown.
Bla bla something something green is less than the other